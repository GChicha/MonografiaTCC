\documentclass[
    12pt,
    oneside,
    a4paper,
    english,
    brazil
]{abntex2}

\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{indentfirst}
\usepackage{color}
\usepackage{graphicx}
\usepackage{microtype}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{csquotes}

\usepackage{tikz}
\usetikzlibrary{positioning}

\usepackage{caption}

\usepackage[brazilian,hyperpageref]{backref}
\usepackage[alf]{abntex2cite}

\usepackage{macros}

\titulo{Previsão de séries temporais por meio de aprendizado de máquina}
\autor{Guilherme Chichanoski}
\local{Maringá}
\data{2018}
\orientador{Valéria Delisandra Feltrim}
\instituicao{Universidade Estadual de Maringá\\
             Centro de Tecnologia --- Departamento de Informática\\
             Bacharelado em Ciência da Computação}
\tipotrabalho{Trabalho de Conclusão de Curso}

\preambulo{Trabalho  de   Conclusão  de  Curso  de   Graduação  apresentado  ao
    Departamento  de  Informática da  Universidade  Estadual  de Maringá,  como
    requisito  parcial  para  obtenção  do  grau  de  Bacharel  em  Ciência  da
    Computação.}

\makeatletter
\hypersetup{
    pdftitle={\@title},
    pdfauthor={\@author},
    pdfsubject={\imprimirpreambulo},
    pdfcreator={LaTeX with abnTeX2},
    pdfkeywords={séries temporais}{arima}{aprendizado de máquina}{redes neurais},
    colorlinks=true,   % false: boxed links; true: colored links
    linkcolor=red,     % color of internal links
    citecolor=green,   % color of links to bibliography
    filecolor=magenta, % color of file links
    urlcolor=blue,
    bookmarksdepth=4
}
\makeatother

\setlength{\parindent}{1.3cm}
\setlength{\parskip}{0.2cm}

\begin{document}

\frenchspacing

\imprimircapa{}

\imprimirfolhaderosto{}

\begin{epigrafe}
    \vspace*{\fill}
    \begin{flushright}
        \textit{``Rogo a você que me lê\\
        A sua boa vontade\\
        Não olhe os error, releve,\\
        Guarde com sinceridade\\
        E busque o melhor fazer\\
        Lendo cordel de verdade.''\\
        Raquel Juvêncio e Filomena Mourão}
    \end{flushright}
\end{epigrafe}

\begin{resumo}
    % TODO: Resumo

    \textbf{Palavras-chave}: séries temporais, arima, aprendizado de máquina,
    redes neurais.
\end{resumo}

\begin{resumo}[Abstract]
    \begin{otherlanguage*}{english}
        % TODO: Abstract

        \textbf{Keywords}: time series, arima, machine learning, neural
        networks.
    \end{otherlanguage*}
\end{resumo}

\textual{}

\pdfbookmark[0]{\contentsname}{toc}
\tableofcontents*
\cleardoublepage{}

\chapter{Introdução}

%VALERIA: Evite usar a 1a pessoa no texto ("podemos..., fizemos...", etc.). Embora essa forma seja comum na escrita científica em inglês, em português não é usual. Eu já corrigi essa questão em toda a parte revisada (até o início dos modelos probabilísticos). Por favor, corrija no restante.

Segundo \citeonline{wiley} prever é a capacidade de predizer valores ou eventos
futuros e  constitui uma  tarefa de grande  importância para  diversos setores,
incluindo governos e industrias. Uma vez  que tal capacidade é parte crucial na
tomada de decisão,  fica evidente a necessidade de se  realizar boas previsões.
No entanto,  fazer boas  previsões pode ser  uma tarefa  extremamente complexa.
Muitos autores  e organizações já realizaram  previsões que, com o  decorrer do
tempo, se mostraram erradas, como no caso  do The New York Times, que previu em
1966  que existiriam  somente 220 000  computadores nos  Estados Unidos  no ano
2000.

Ainda conforme  \citeonline{wiley}, as  previsões são classificadas  como sendo
de  curto,  médio  e  longo  prazo,   sendo  o  prazo  definido  na  frequência
das  observações.  Quando denominadas  de  curto  prazo, são  previstas  poucas
observações  a frente  do tempo  atual. Já  previsões de  médio prazo  podem se
estender por algumas observações no futuro.  Por fim, previsões que envolvem um
período maior  no futuro são chamadas  de longo prazo. Ainda  conforme o autor,
predições de médio e longo prazo são mais difíceis de se realizar e suscetíveis
a fatores externos.

% FIXME Acredito que deveria estar nos trabalhos relacionados
%Em  \citeonline{giebel2011state} o  autor  realiza a  predição  da geração  de
%energia eólica, a produção é dada em função da capacidade na região instalada,
%o vento,  no entanto, é  um elemento volátil  e sendo assim  existirá momentos
%quais o  uso de outras  fontes será necessária,  contudo, é preciso  ter certo
%conhecimento prévio,  pois, o ligamento  de uma  usina como aquelas  movidas a
%gasóleo podem levar até  duas horas. Logo prever duas horas  a frente pode ser
%crucial  para  garantir o  abastecimento  de  energia  a uma  região,  podendo
%impactar no cotidiano e economia de uma população.

Para a realização da previsão é necessária  a compreensão do evento que se quer
prever. Quando  existe uma relação temporal  entre as observações do  evento em
questão,  i.e., o  evento  ocorre  em uma  determinada  sequência  no tempo,  é
necessário organizar  as informações  de forma a  evidenciar a  dependência das
observações com  seus estados anteriores.  Nesse caso, as  observações passadas
compõem uma  série temporal, a  partir da qual  é possível realizar  medições e
produzir modelos capazes de expressar  matematicamente o comportamento da série
em  função de  suas  observações  anteriores, permitindo  assim  a predição  de
estados futuros.

Conforme  mencionado,   as  séries  temporais  são   compostas  de  observações
sequenciais ao  longo do  tempo~\cite{wiley}. Como exemplo,  a \autoref{serie0}
mostra uma série gerada utilizando-se um processo de caminhada aleatória. Sendo
essas observações  separadas unicamente pelo  tempo, pode-se obter os  dados em
diferentes intervalos,  como observações diárias, semanais  ou anuais. Conforme
\citeonline{ehlers},  devido  à  caraterística  estocástica  do  processo,  uma
observação se define em função de suas antecessoras.

\begin{figure}[ht]
    \centering
    \caption{Série gerada para exemplo}\label{serie0}
    \includegraphics[width=.5\linewidth]{images/serie_exemplo.png}
    \source{Elaborado pelo autor}
\end{figure}

Considerando  então  que  a  série  apresentará  comportamento  estocástico,  é
possível  propor  modelos  que  serão  capazes  de  aproximar  o  comportamento
da  série.  Os  modelos  comumente  utilizados para  essa  tarefa  são  aqueles
probabilísticos, mais especificamente o ARIMA\@, proposto por \citeonline{box}.
Também é possível utilizar modelos criados a partir da aplicação de técnicas de
aprendizado de máquina,  que vem se apresentando como  uma alternativa poderosa
em muitas aplicações.

Com o  constante interesse na  aplicação e  a identificação das  capacidades de
técnicas de  aprendizado, fica  evidente a importância  de observar  como esses
modelos se comparam com os estatísticos. Dessa forma, o objetivo deste trabalho
foi comparar o desempenho de modelos  estatísticos e baseados em aprendizado de
máquina na previsão de uma  série de característica econômica. Especificamente,
foram  avaliados  o  modelo  estatístico  ARIMA  e  um  modelo  de  aprendizado
de  máquina baseado  em  redes  neurais artificiais  de  múltiplas camadas.  Os
resultados indicaram que  os modelos tiveram desempenhos  semelhantes nos dados
utilizados nesse trabalho.

% Como  forma de  comparar desempenhos  e  buscar compreender  as técnicas  que
% poderiam ser utilizadas para a previsão, este trabalho realizou a previsão de
% uma série de característica econômica utilizando ambas metodologias.

% TODO: Introduzir modelos ARIMA com exemplos de artigos

% FIXME Mais adequado na parte de trabalhos relacionados
%vez mais  notórias pelos bons resultados  que oferecem. \citeonline{artigoEx3}
%Em contrapartida, técnicas  de aprendizado de máquinas estão  se tornando cada
%aplicou  métodos  de aprendizado  de  máquina  possibilitando a  previsão  com
%bons  resultados. Pelo  fato  dos modelos  estatísticos fornecerem  resultados
%satisfatórios para predições e estarem bem difundidos na comunidade acadêmica,
%é  comum  que  trabalhos  como \citeonline{artigoEx4}  compare  os  resultados
%obtidos  a  partir  de  aprendizado   de  máquina  com  modelos  de  abordagem
%estatísticas. Para modelos de aprendizado se  destaca aqueles com uso de redes
%neurais  artificiais  por serem  capazes  de  obter bons  resultados  conforme
%analisado  por \citeonline{zhang},  o  autor ainda  apresenta outros  exemplos
%quais os autores obtiveram resultados superiores ao método estatístico.

O    restante   desta    monografia    está   organizada    como   segue.    No
\autoref{chap:fundTeor}  é apresentada  a  fundamentação  teórica do  trabalho,
incluindo os principais métodos de  previsão de séries temporais empregados. No
\autoref{chap:desenv} são  descritos os passos metodológicos  empregados para a
desenvolvimento tanto do  modelo estatístico quanto de  aprendizado de máquina.
Os  resultados obtidos  com base  nos modelos  construídos são  apresentados no
\autoref{chap:result} e  apresentada as  constatações feitas em  ambos modelos.
Por  fim,  no  \autoref{chap:concl}  é  apresentada  a  conclusão  do  que  foi
realizado.

\chapter{Fundamentação teórica}\label{chap:fundTeor}

\section{Previsão}
Segundo  \citeonline{wiley},  o  processo  de previsão  pode  ser  dividido  em
diversas atividades, dispostas a seguir:

\begin{enumerate}
    \item Definição do problema\\
        Envolve  definir e  entender  a  tarefa de  previsão  a ser  realizada,
        considerando o prazo a ser previsto e definindo os dados necessários.
    \item Coleta dos dados\\
        Envolve a coleta  dos dados necessários de acordo com  as definições da
        atividade anterior.
    \item Análise dos dados\\
        Atividade de alta  importância para a seleção do  modelo mais adequado.
        Nessa  etapa   são  utilizadas  observações  gráficas   e  extração  de
        características para identificar padrões  que corroborem na escolha dos
        parâmetros. Também são identificadas  observações problemáticas e, caso
        necessário, aplicadas as devidas correções.
    \item Seleção e verificação do modelo\\
        A partir  da análise  feita na atividade  anterior, será  selecionado o
        modelo, analisando-se  também o comportamento com  os dados fornecidos.
        Como  método de  verificação são  utilizadas métricas  que favoreçam  a
        comparação.
    \item Avaliação do modelo\\
        Atividade na qual se avalia como  o modelo se comporta com novos dados,
        normalmente realizada  com observações  excluídas dos  dados utilizados
        nas atividades anteriores. As  observações separadas para avaliação são
        utilizadas apenas para essa finalidade.
    \item Publicação do modelo\\
        Com o modelo devidamente selecionado e avaliado, o mesmo é instalado em
        ambiente de produção, observando-se  as alterações necessárias para que
        novos dados sejam inseridos corretamente.
    \item Monitoramento do desempenho do modelo\\
        Deve-se continuamente  avaliar como  o modelo  aplicado se  comporta em
        relação ao ambiente, já que o ambiente é algo volátil.
\end{enumerate}

Essas  atividades  normalmente  são  realizadas em  ordem  como  exposta.  Vale
observar  ainda  que   se  os  resultados  da  atividade   de  avaliação  forem
insatisfatórios, deve-se  retornar à atividade  anterior e refazer  a avaliação
até que um modelo que obedeça às especificações seja encontrado.

\section{Séries temporais}\label{sec:seriesTemporais}

Como  exposto anteriormente,  séries  temporais são  compostas por  observações
sucessivas  feitas ao  longo do  tempo. Cabe  destacar ainda  que essas  séries
se  caracterizam   pelo  fato  de   suas  observações  serem   dependentes  das
observações  anteriores. Além  disso,  tais  séries demonstram  características
como  tendência e  sazonalidade.  A tendência  caracteriza  o comportamento  de
crescimento/decrescimento da série, o que  pode levar a observações futuras com
valores  menores ou  maiores. A  sazonalidade caracteriza  padrões cíclicos  em
função do tempo, comumente tomando períodos semanais, mensais ou anuais.

Uma série é descrita matematicamente pelo conjunto $\{X(t): t \in T\}$, podendo
$t$ ser  um tempo  contínuo ou  discreto. O  tempo $t$  é dito  contínuo quando
se  possui  observações  $X(t)$  para  todo $t$  em  $T$,  sendo  $T  \subseteq
\mathbb{R}^{+}$. O tempo $t$ é discreto  quando entre as observações $X(t_i)$ e
$X(t_{i+1})$ existe um  intervalo igual de tempo, normalmente dado  na forma de
uma sequência, $T = \{1, 2, \ldots, n\}$, sendo $n$ o número de observações.

Segundo  \citeonline{ehlers}, uma  série  temporal  classicamente é  decomposta
seguindo a \autoref{eq:timeseries}, sendo $t$ usado para denotar o tempo, logo,
é parte fundamental entender o comportamento segundo essas três componentes.

\begin{equation}
    \label{eq:timeseries}
    X_t = Tendência_t + Sazonal_t + Aleatório_t
\end{equation}

\subsection{Série estacionária}\label{sec:estacionaria}

Um  conceito   importante  para  a  análise   de  séries  temporais  é   o  seu
caráter  estacionário.  Um  processo  é  dito estacionário  se  todas  as  suas
características  comportamentais não  se  alteram ao  longo  do tempo.  Segundo
\citeonline{timeseriesExample} não existe  um limiar que defina  uma série como
estacionaria, mas pode  definir como estacionário um processo  se desenvolve no
tempo em  torno da média, de  modo que a escolha  de uma origem dos  tempos não
é  importante.  Segundo  \citeonline{ehlers},  uma série  é  dita  estritamente
estacionária  quando  a  distribuição  de probabilidade  conjunta  de  $X(t_1),
\ldots, X(t_k)$ é igual a de $X(t_1 + \tau), \ldots, X(t_k + \tau)$.

Ainda segundo \citeonline{ehlers}, a definição  estrita de série estacionária é
dificilmente  aplicada,  então  usualmente  se utiliza  a  definição  de  série
fracamente estacionária,  que se define com  base no critério da  mesma possuir
função média  constante. Dessa forma,  no decorrer  deste trabalho, se  usará a
definição  de  série fracamente  estacionária  para  se  tomar uma  série  como
estacionária.

Em  termos matemáticos,  usa-se a  \autoref{eq:westacionaria} para  definir que
variância  de um  elemento da  série ($z_t$)  deve ser  semelhante à  média. Em
outras  palavras, o  deslocamento da  origem do  tempo $t$  por uma  quantidade
$\tau$ não  exerce efeito  na distribuição  conjunta da  série. Assim,  o valor
esperado para a série em determinado momento não será dada em função do tempo.

\begin{equation}
    \label{eq:westacionaria}
    E(z_t) = \mu_t = \mu
\end{equation}

% FIXME Dada em função de que??


%TODO Adicionar referência ao Livro Time Series by exmples

%TODO Adicionar referência ao teste de Dockey Fuller

% VALERIA: Deixe para mostrar o exemplo da série estacionária pós-diferenciação
% na seção que fala  sobre a diferenciação. Neste ponto do  texto ficou fora de
% contexto. Ou, se  vc quer mostrar um exemplo, mostre  uma série originalmente
% estacionária. Além  disso, nesse caso, vc  tem que explicar melhor  a figura.
% Por exemplo,  qual(is) característica(s) do  gráfico da série me  diz(em) que
% ela é  estacionária? Dizer  que a  observação do gráfico  é suficiente  não é
% suficiente. ;)

Segundo  \citeonline{timeseriesExample} embora  exista testes  como o  de Dikey
Fuller  descrito  em  \citeonline{dickey}  para a  prova  de  estacionariedade,
é  suficiente  a observação  gráfica  da  série.  Caso  não seja  conclusiva  a
observação \citeonline{timeseriesExample} orienta obter  o gráfico da função de
autocorrelação,  e  se  observada  a  existência  de  mais  de  20  correlações
significativas pode-se classificar a série como não estacionaria.

\subsection{Sazonalidade e tendência}

Conforme   definido  por   \citeonline{ehlers},   a  sazonalidade   caracteriza
repetições  de comportamento  de uma  série em  um período  $s$. A  presença da
sazonalidade,  em geral,  é facilmente  observada na  representação gráfica  da
série, conforme exemplificado no gráfico  da \autoref{fig:co2}. Nesse gráfico é
apresentada uma série  temporal real que registra a mudança  na concentração de
$CO_2$ na atmosfera. Observando o gráfico, é possível notar que há sazonalidade
de periodicidade anual, devido ao gráfico apresentar formato de serra e está se
apresentar em repetição anual.

Ainda  no  gráfico  da  \autoref{fig:co2},  também  é  possível  notar  que  há
uma  tendência de  crescimento na  série. Segundo  \citeonline{ehlers}, não  há
uma  definição exata  de  tendência, mas  normalmente a  mesma  é associada  ao
comportamento  de  mudança  das  observações  ao longo  de  um  vasto  período.
Uma  série  com tendência  pode  ser  descrita  como  a função  apresentada  na
\autoref{eq:tendencia},  na  qual $\alpha$  e  $\beta$  são os  coeficientes  e
$\epsilon_t$ é  o erro. O coeficiente  $\beta$ define a taxa  de crescimento da
série  e, desse  modo, $\beta$  pode  ser entendido  na  forma $\beta  = x_t  -
x_{t-1}$.

\begin{equation}
    \label{eq:tendencia} X_t = \alpha + \beta_t + \epsilon_t
\end{equation}

Esse entendimento de série  com tendência, segundo \citeonline{ehlers}, permite
encontrar uma  função polinomial representativa  da série na forma  mostrada na
\autoref{eq:tendenciaSerie}.

\begin{equation}
    \label{eq:tendenciaSerie}
    X_t = \beta_0 + \beta_1t + \beta_2t^2 + \cdots + \beta_{p}t^p + \epsilon_t
\end{equation}

% Um exemplo real de uma série  temporal que apresenta tendência e sazonalidade
% é mostrado  no gráfico  na \autoref{fig:co2}. Essa  série registra  a mudança
% na  concentração  de $CO_2$  na  atmosfera,  sendo,  portanto, uma  série  de
% característica natural.  Observando o gráfico,  é fácil notar a  tendência de
% crescimento da série e sua sazonalidade de periodicidade anual.

\begin{figure}[ht]
    \centering
    \caption{Leituras de $CO_2$ na atmosfera.}\label{fig:co2}
    \includegraphics[width=.5\linewidth]{images/co2.png}
    \source{\citeonline{co2data}}
\end{figure}

\subsubsection{Filtros}

Em  algumas séries  a  tendência pode  não estar  evidente  devido ao  processo
aleatório. Por conta disso, pode ser  necessária a aplicação de filtros que têm
como objetivo obter  uma série suavizada que possibilite  observar a tendência.
Um desses filtros é apresentado na \autoref{eq:filtro}~\cite{ehlers}.

\begin{equation}
    \label{eq:filtro}
    y_t = \sum_{j = -q}^{s}{a_{j}x_{t+j}}
\end{equation}

Na \autoref{eq:filtro}, $a_j$  é um coeficiente a ser aplicado  a cada termo da
soma de forma a aplicar um peso a este, sendo observado que $\sum{a_j} = 1$.

A  \autoref{eq:yjfiltro}  é  conhecida  por   fornecer  o  cálculo  das  médias
móveis,  permitindo  suavizar  a  série,  mantendo  a  tendência.  A  aplicação
do  filtro  de médias  móveis  nos  dados das  leituras  de  $CO_2$ resulta  na
\autoref{fig:co2filtrado}, que evidencia de forma independente a tendência após
a remoção da sazonalidade, por meio da suavização utilizando como parâmetro $q$
seu período cíclico.

\begin{equation}
    \label{eq:yjfiltro}
    y_t = \frac{1}{2q + 1}\sum_{j=-q}^{q}{x_{t+j}}
\end{equation}

\begin{figure}[ht]
    \centering
    \caption{Leituras de $CO_2$ filtrada utilizando médias móveis com $q$ igual
        a $52$, devido à sazonalidade ser anual, ou seja, $52$
        semanas.}\label{fig:co2filtrado}
    \includegraphics[width=.5\linewidth]{images/co2_filtered.png}
    \source{Elaborado pelo próprio autor a partir de \citeonline{co2data}}
\end{figure}

\subsubsection{Diferenciação}\label{sec:diff}

Outra tarefa a ser observada em relação  ao entendimento de tendência é a forma
na qual é removida. O método mais  simples para remoção da tendência é subtrair
de  cada valor  observado  o  valor do  seu  antecessor,  conforme descrito  na
\autoref{eq:diferenciacao}. Normalmente,  uma única diferenciação  é suficiente
para remover  a tendência, porém em  séries com componente sazonal  podem vir a
ser necessárias mais de uma em um \textit{lag} diferente.

\begin{equation}
    \label{eq:diferenciacao}
    y_t = x_t - x_{t-1}
\end{equation}


O gráfico  da \autoref{fig:co2diff} mostra o  resultado obtido para a  série de
leituras de $CO_2$ após uma diferenciação. Pelo gráfico é possível perceber que
a série resultante  se aproxima de uma série com  função média constante, dando
evidência  a  componente  sazonal  já  que  a  variação  do  gráfico  apresenta
unicamente um forte comportamento repetitivo.

\begin{figure}[ht]
    \centering
    \caption{Série da leitura do $CO_2$ na atmosfera com uma
        diferenciação}\label{fig:co2diff}
    \includegraphics[width=.5\linewidth]{images/co2_diff.png}
    \source{Elaborado pelo autor a partir de \citeonline{co2data}}
\end{figure}

\section{Modelos probabilísticos}

Conforme  apresentado anteriormente,  as séries  temporais podem  ser previstas
utilizando-se modelos  estatísticos. Segundo \citeonline{ehlers}, isso  se deve
ao  seu caráter  estocástico, uma  vez  que cada  observação possui  correlação
com  as  observações  imediatamente   antecessoras,  diferentemente  de  séries
determinísticas, as quais têm seu estado  definido por uma função matemática ou
um sistema para o qual a saída é dependente apenas das entradas atuais.

Um modelo comumente utilizado para a  previsão de séries temporais é o ARIMA\@.
Descrito por  \citeonline{box}, esse  modelo caracteriza a  série em  termos de
três  parâmetros $(p,d,q)$,  sendo  cada  um associado  a  um  processo: $p$  é
associado a processos  auto-regressivos, $d$ a integração e $q$  a processos de
médias móveis.

A   definição  dos   valores   desses  parâmetros   depende   da  análise   das
características da  série. \citeonline{box}  descreveu algumas  ferramentas que
podem auxiliar nessa análise, entre elas a análise da função de autocorrelação.

\subsection{Função de autocorrelação}\label{sec:corre}

Como  o nome  sugere, a  função de  autocorrelação mede  a correlação  entre as
observações  de uma  série em  diferentes períodos.  Considerando-se uma  série
temporal $X$, calcula-se  a correlação entre seus valores com  uma defasagem de
tempo $k$,  sendo essa defasagem  a distância entre  o valor analisado  $X_t$ a
observação  $X_{t-k}$.  Por exemplo,  supondo  uma  série de  100  observações,
pode-se chamar de $X'$ a série  correspondente às 99 primeiras observações e de
$X''$ a série correspondente às últimas  99 observações. Nesse caso, tem-se uma
defasagem (ou \text{lag})  de 1 período. Assim a função  de autocorrelação será
dada segundo a \autoref{eq:autocorrelacao}.

\begin{equation}
    \label{eq:autocorrelacao}
    r_k = \frac{\sum_{t=1}^{n-k}{(x_t - \overline{x})(x_{t+k} -
    \overline{x})}}{\sum_{t=1}^{n}{(x_t - \overline{x})^2}}
\end{equation}

Segundo  \citeonline{ehlers},  a  função   de  autocorrelação,  quando  plotada
para  os  $k$-ésimos  primeiros  coeficientes,  é  chamada  de  correlograma  e
constitui-se em uma ferramenta importante para  as análises. Como um exemplo, a
\autoref{fig:correlogramaCo2}  apresenta o  correlograma  com  as 25  primeiras
defasagens das leituras de concentração  de $CO_2$ na atmosfera. Nesse gráfico,
também  é  exibido o  intervalo  de  confiança  calculado para  o  correlograma
(destacado  em  azul).  Segundo   \citeonline{ehlers},  é  preciso  definir  um
intervalo de  confiança para o  correlograma para se definir  quais correlações
são relevantes e  quais não. De forma que todas  as correlações relevante estão
fora desse  intervalo de  confiança. Assim, se  todas as  correlações estiverem
dentro do  limite a série  é caracterizada como um  ruído branco, ou  seja, seu
comportamento não permite  modelagem. Para encontrar o  intervalo de confiança,
\citeonline{ehlers} recomenda utilizar a seguinte equação $\pm{}1,96/\sqrt{n}$,
sendo $n$ o número de observações da série.
% Encontrei um calculo um pouco diferente para o intervalo de confiança no
% livro Time Series By Examples, lá está colocado como +-2/sqrt(n)

\begin{figure}[ht]
    \centering
    \caption{Gráfico da função de autocorrelação das leituras de
        $CO_2$}\label{fig:correlogramaCo2}
    \includegraphics[width=.5\linewidth]{images/acf_co2.png}
    \source{Elaborado pelo autor a partir de \citeonline{co2data}}
\end{figure}

Pela \autoref{fig:correlogramaCo2}  podemos concluir que as  leituras do $CO_2$
apresentam  uma  tendência, e  ainda  por  apresentar todos  valores  positivos
podemos afirmar que  crescerá ao longo do tempo. Como  a série possui tendência
temos  de  fazer  uma   diferenciação,  como  disposto  na  \autoref{sec:diff},
para  remoção  dessa componente,  vemos  a  série  após essa  diferenciação  na
\autoref{fig:co2diff} e o  correlograma após a diferenciação pode  ser visto na
\autoref{fig:acfco2diff}, nesse  novo gráfico é  percebido que a  componente da
tendência foi  realmente removida  após uma  diferenciação, tornando  visível a
componente sazonal, vemos  isso pela alternância das  correlações observadas no
correlograma.

\begin{figure}[ht]
    \centering
    \caption{Gráfico de função de autocorrelação da diferenciação da série de
        $CO_2$}\label{fig:acfco2diff}
    \includegraphics[width=.5\linewidth]{images/acf_co2_diff.png}
    \source{Elaborado pelo autor a partir de \citeonline{co2data}}
\end{figure}

% TODO: Citar as seções nas quais o correlograma é apresentada em outros
%cenários

\subsection{ARIMA}

O  modelo  ARIMA  já  introduzido  na seção  anterior  possui  três  parâmetros
essenciais $(p,q,d)$ sendo  $p$ repensável por definir o  numero de observações
considerados  no  processo auto  regressivo,  $q$  o numero  de  diferenciações
necessárias para a remoção da tendencia e $d$ o numero de termos no processo de
medias móveis.

\subsubsection{AR --- Processo auto regressivo}

% TODO Melhorar descrição da forma que é encontrado os coeficientes e a
% utilização do ACF e PACF para identificação do p

Segundo  \citeonline{ehlers}  um  processo  $X_t$  é  chamado  auto  regressivo
de   ordem   $p$,   ou   $AR(p)$,   quando   temos   $X_t$   dado   segundo   a
\autoref{eq:aregressivo}.  Nesse  caso $\alpha$  são  os  coeficientes a  serem
calculados.

\begin{equation}
    \label{eq:aregressivo}
    X_t = \sum_{i = 1}^{p}{\alpha_{i}X_{t-i}}
\end{equation}

Como observado  na \autoref{eq:aregressivo}, é  um modelo útil se  for razoável
assumir que o valor atual depende somente de seus antecessores imediatos.

\subsubsection{MA --- Processo de médias móveis}

% TODO Melhorar descrição da forma que é encontrado os coeficientes e a
% utilização do ACF e PACF para identificação do q

Segundo \citeonline{timeseriesExample} o processo de  médias móveis é dado como
a média  dos termos passados  e correntes  e pode ser  descrito matematicamente
segunda a \autoref{eq:pmediasmoveis}. Sendo os  valores $\epsilon$ o passo dado
no passeio aleatório, já que  podemos considerar a série gerada recursivamente.
Como   exemplo   temos   a  \autoref{eq:passeioAleatorio}   onde   considerando
$\epsilon_0 = 0$ e somente um coeficiente $\theta$.

\begin{equation} \label{eq:passeioAleatorio}
    \begin{split}
        & \epsilon_1 = X_1 \\
        & \epsilon_2 = X_2 + \theta \epsilon_1 \\
        & \vdots \\
        & \epsilon_t = X_t + \theta \epsilon_{t-1}
    \end{split}
\end{equation}

\begin{equation}
    \label{eq:pmediasmoveis}
    X_t = \epsilon_t - \theta_1\epsilon_{t-1} - \theta_2\epsilon_{t-2} - \cdots - \theta_{q}\epsilon_{t-q}
\end{equation}

\subsubsection{ARMA --- Modelo misto}

Combinando o  processo AR e MA  podemos obter um modelo  extremamente útil para
descrever  séries temporais.  E a  junção dos  modelos pode  ser expressa  pela
\autoref{eq:arma}.

Então segundo  \citeonline{timeseriesExample} se  considerarmos $X_t$  como uma
série estacionaria, teremos  o processo AR relacionando a  observação atual com
as  $p$  observações anteriores  e  o  processa  MA apresentando  as  defasagem
passadas e presente.

\begin{equation}
    \label{eq:arma}
    X_t = \sum_{i = 1}^{p}{\alpha X_{t-i}} + \epsilon_t - \sum_{j = 1}^{p}{\theta \epsilon_{t-i}}
\end{equation}

\subsubsection{Integração}

Em  casos  que a  série  analisada  apresenta  não estacionariedade  segundo  a
definição dada  na \autoref{sec:estacionaria}, é necessário  a transformação em
uma série estacionaria, isso pode  ser facilmente realizado utilizando o método
de  diferenciação  descrito na  \autoref{sec:diff},  assim  podemos aplicar  de
forma  adequada o  procedimento  de \citeonline{box}  para  produzir um  modelo
probabilístico que poderá ser utilizado na atividade de previsão da série.

% TODO Referencias??
Normalmente  uma diferenciação  é suficiente  para remover  a tendencia  de uma
série  e a  transformar em  uma série  estacionária, entretanto  em séries  que
apresentem a componente  sazonal pode vir a ser necessária  a aplicação de duas
ou  mais  diferenciações e  em  casos  da  aplicação  de modelos  SARIMA,  essa
diferenciação é aplicada com uma distância  $l$, com esse valor sendo dado pela
sazonalidade da  série, no entanto,  esse modelo  sazonal não foi  discutido no
decorrer do desenvolvimento.

\subsection{Seleção do modelo}

De  acordo  com \citeonline{box}  a  identificação  do  modelo pode  ser  feita
a  partir  da  análise  gráfica  da  FAC e  FACP,  que  foram  apresentados  na
\autoref{sec:corre}, podendo contar com a ajuda de outros testes para validação
da estacionariedade da série.

% FIXME Corrigir inicio
O método proposto por \citeonline{box} observa o comportamento da correlação de
forma que  para identificar  a ordem  do AR,  $p$, é  suficiente analisar  se o
gráfico do FAC  apresenta decaimento exponencial e FACP apresenta  uma quebra a
partir do elemento $p$  do gráfico. Já a identificação da  ordem do processo de
médias móveis  é feita de modo  análogo, porem o  $q$ é dado pela  elemento que
apresenta  a quebra  no gráfico  do FACP  enquanto o  gráfico do  FAC apresenta
decaimento exponencial. Para modelos híbridos a  análise é mais complexa e pode
ser necessária a verificação do FAC residual.

Se não for  possível identificar a série a partir  deste procedimento, pode ser
que a  série apresente  tendencia. No  caso de  existir tendência  é necessária
a  realização  de  uma  ou  mais diferenciações,  com  essa  nova  série  agora
estacionaria é refeito as verificações e determinadas as ordens.

No caso acima o  modelo obtido ou é da forma $AR(p)$ ou  $MA(q)$ porem em casos
de modelos híbridos ambas funções  devem apresentar comportamento de decaimento
a partir do  $p$ para o FAC  e $q$ para FACP\@.  Na \autoref{tab:facpacf} temos
esse procedimento de seleção do modelo de forma sumarizada.


\begin{table}[ht]
    \centering
    \caption{Modelo conforme FAC e FACP}\label{tab:facpacf}
    \begin{tabular}{l l l}
        \multicolumn{1}{c}{Modelo} & \multicolumn{1}{c}{FAC} & \multicolumn{1}{c}{FACP} \\
        \toprule
        Série aleatória  & 0                          & 0                      \\
        AR (1)           & decaimento exponencial     & 0, $k$ > 2             \\
        AR (p)           & decaimento para zero       & 0, $k$ > $p$           \\
        MA (1)           & 0                          & decaimento oscilatório \\
        ARMA (p, q)      & decaimento a partir de $p$ & decaimento a partir de $q$
    \end{tabular}
    \source{\citeonline{ehlers}}
\end{table}

% FIXME Repetitivo
Porem, segundo  \citeonline{vinay} essa  forma nos  fornece modelos  que servem
somente  como uma  boa aproximação,  para determinação  de um  modelo realmente
eficiente  pode  ser necessário  a  execução  de  um  grande número  de  testes
exaustivos,  e  utilizando de  alguma  métrica  selecionar  o modelo  que  seja
parcimonioso  e que  forneça  bons  resultados, para  isso  podemos comparar  os
diversos testes a partir da minimização do critério de informação de Akaike que
segundo  \citeonline{ehlers} propicia  a identificação  de um  modelo ao  mesmo
tempo parcimonioso e representativo para a série analisada.

\subsection{Determinação dos coeficientes}

Por fim, para completa construção  do modelo apresentado na \autoref{eq:arma} é
necessária a obtenção dos coeficientes  do processo autorregressivo e de médias
móveis. Para  essa tarefa  segundo \citeonline{yinay} é  comum a  utilização do
estimador de \textit{likelihood}, ou mais precisamente a maximação da função de
\textit{likelihood}.

Essa  maximização   é  descrita   por  \citeonline{statiticalML}   da  seguinte
forma.  Considerando  uma função  $q(x;\theta)$  que  nos retorna  a  densidade
probabilística de uma entrada $x$ com um conjunto de parâmetros a ser otimizado
$\theta$ de dimensão $b$, o objetivo é a maximização da \autoref{eq:likelihood}
que nos retorna a capacidade dos parâmetros em aproximar a série.

\begin{equation}\label{eq:likelihood}
    L(\theta) = \prod_{i=1}^{n}{q(x_i;\theta)}
\end{equation}

% TODO Descrever superficialmente o método de Yule Walker

\section{Aprendizado de Máquina}

Computadores se utilizam de algorítimos  para realizar processamento de dados e
solucionar  problemas.  Porém,  para  determinados problemas,  não  é  possível
definir um  algoritmo, seja porque o  seres humanos não conseguem  explicar seu
conhecimento ou  esse conhecimento é  muito complexo para ser  explicitado, ou,
ainda, porque  o conhecimento  e a  solução do  problema muda  com o  passar do
tempo.  Um exemplo  de tal  situação seria  a classificação  de um  e-mail como
\textit{spam} ou legitimo.  Definir as características que fazem  um e-mail ser
considerado \textit{spam}  pode se  tornar um problema  complexo, especialmente
considerando-se que  a definição  de \textit{spam}  pode variar  com o  tempo e
usuário.

Conforme \citeonline{ethem}, tarefas como a identificação de \textit{spam}, que
não apresentam  uma solução  evidente, mas  que podem  ser resolvidas  por meio
da  identificação  de padrões  a  partir  de um  conjunto  de  dados, são  boas
candidatas à aplicação  de técnicas de aprendizado de  máquina. Entretanto para
classificarmos esse sistema como inteligente não  é suficiente que o mesmo seja
capaz de inferir padrões  de uma base, precisamos que este  ainda seja capaz de
se adaptar a mudanças e aprender com isso.

%Considerando  a definição apresentada e 
\citeonline{machineLearning} descreve aprendizado de máquina como a habilidade  de algoritmos reconhecer padrões em um conjunto de dados. 
%VALERIA: As duas atividades que vc descreve são características de AM supervisionado. Vc não falou nada sobre isso. AM supervisionado é o tipo mais comum de AM, mas não é o único. Além deles, temos AM não-supervisionado (que inclui as atividades de associação e agrupamento) e AM por reforço.
Esse aprendizado de padrões pode ser aplicado, por exemplo, nas seguintes atividades:
\begin{itemize}
    \item Classificação\\
        Tarefa de encontrar  o  mapeamento  de  uma   entrada  a  uma  ou mais categorias de um conjunto pré-definido.
        %VALERIA: Vc não mostrou o exemplo da classificação de números ainda
        %,  como  no exemplo  na  classificação  dos   números,  apresentada  no  início  da seção.  
        Um exemplo desse tipo de tarefa seria a classificação de dígitos manuscritos nas classes de 0 a 9. Sendo a classificação uma das tarefas de aprendizado de máquina mais comuns, é possível encontrar  exemplos do seu uso em diversos cenários, desde a classificação de textos até a identificação de riscos em aplicações financeiras.
    \item Regressão\\
        Tarefa de mapear uma entrada, representada por meio de um conjunto  de valores, a uma saída em  $\mathbb{R}$. 
        %VALERIA: tem certeza que esse trabalho fez regressão? Se o valor previsto não for contínuo, não caracteriza regressão.
        Como um exemplo desse tipo de tarefa, \citeonline{regressao} utilizou redes  neurais   artificiais para encontrar um modelo que permitisse a previsão da  demanda de  uso de energia elétrica,  mapeando a carga atual e informações climáticas à carga futura.
\end{itemize}

%VALERIA: Esse exemplo é bom, mas está mal explicado. Além disso, ele exemplifica apenas a atividade de classificação e vc não disse porque vai explicar essa atividade e não a outra (regressão).
%Vc tb está emendando o parágrafo todo em uma única frase. Não pode. Um parágrafo é composto de várias frases! Use o ponto final!
%Deixei o parágrafo abaixo comentado para vc ver como vc tinha feito e veja como eu o separei em frases menores no parágrafo a seguir.
%Um exemplo de uso de aprendizado de máquina é a identificação de caracteres  numéricos escritos à mão, esse  exemplo  é   apresentado  por \citeonline{machineLearning} é  descrito como  um problema de  classificação na qual uma imagem  de dimensões $28 \times 28$ pixeis é dada como  entrada em um sistema e este deve atribuir uma classificação que descreve qual o número que a figura representa,  um conjunto  de exemplo  dessas imagens  pode ser  visto na \autoref{fig:numeroClassi}.
Um exemplo de uso de aprendizado de máquina é a identificação de caracteres  numéricos escritos à mão. Apresentado por \citeonline{machineLearning}, esse exemplo é descrito como  um problema de  classificação no qual uma imagem  de dimensões $28 \times 28$ pixeis é dada como  entrada para um sistema que deve atribuir uma categoria que descreve qual o número que a figura representa.  Um conjunto de exemplos de tais imagens  pode ser  visto na \autoref{fig:numeroClassi}.

\begin{figure}[ht]
    \centering
    \caption{Exemplo de entrada para o algorítimo de
        classificação}\label{fig:numeroClassi}
    \includegraphics[width=.5\linewidth]{images/numeroClassificacao.png}
    \source{\citeonline{machineLearning}}
\end{figure}

No exemplo apresentado na \autoref{fig:numeroClassi} podemos entender a tarefa como um sistema no qual $x$  é a  entrada  e $\hat{y}$  é a  saída.
Matematicamente, podemos expressar da  forma vista  na \autoref{eq:sisCla}.  A saída será na forma  de um conjunto de números variando de 0  a 1 expressando a probabilidade  de  $x$ pertencer  à  classe  $\hat{y}_i$  onde  $i$ é o valor expressado na imagem.

\begin{equation}
    \label{eq:sisCla}
    f(x) = \hat{y}
\end{equation}

\subsection{Redes Neurais artificiais}

Segundo  \citeonline{haykin2009}  a pesquisa  em  redes  neurais artificiais  é
motivada pelo entendimento que o cérebro  humano realiza o processamento de uma
forma  completamente diferente  dos computadores  convencionais. Essa  forma de
realizar  o processamento  realizado  pelo cérebro  é  altamente complexa,  não
linear e altamente paralela. A unidade de processamento e organização básica de
um cérebro são  os neurônios, o autor ainda lhe  confere superior capacidade na
realização de  tarefas como  reconhecimento de padrões  do que  os computadores
digitais.

Os animais  já nascem com  o cérebro possuindo  certa estruturas que  estes vão
precisar  durante sua  vida,  porem este  é concebido  ainda  de maneira  muito
plastica, ou seja,  possuindo ainda a capacidade de na  fase de aprendizado ser
capaz de se adaptar ao contexto em  que vai se desenvolver. Este mesmo conceito
de  plasticidade  também será  utilizado  para  a  modelagem de  redes  neurais
artificiais~\cite{haykin2009}.

\subsubsection{\textit{Perceptron}}

Como  já  colocado, as  redes  neurais  possuem  o  neurônio como  elemento  de
processamento,  este em  redes artificiais  associamos ao  \textit{perceptron},
descrito primeiramente  por Rosenblatt em  1962, e  tem sua função  definida em
\autoref{eq:perceptron}  sendo  dado  como  a  soma  ponderada  por  $w_i$  das
entradas,  $x_i$. Visualmente  o \textit{perceptron}  é representado  segundo a
\autoref{fig:perceptron}.

\begin{equation}\label{eq:perceptron}
    v(x) = \sum_{i=1}^{m}{w_i  x_i + b}
\end{equation}

\begin{figure}[ht]
    \centering
    \caption{Representação gráfica de um \textit{perceptron}}\label{fig:perceptron}
    \includegraphics[width=.5\linewidth]{images/perceptron.png}
    \source{\citeonline{haykin2009}}
\end{figure}

Após  a soma  ponderada é  aplicada ao  resultado $v$  uma função  de ativação,
classicamente essa função é dado como uma função de limiar, ou seja, se o valor
resultado da soma  ponderado for maior que um valor  determinado o resultado do
processamento do neurônio artificial é 1 caso contrario 0~\cite{knight}.

Um exemplo  dessa função de limiar  é dada da forma  da \autoref{eq:funLimiar},
nesse exemplo a função resulta em 1 quando  o valor do perceptron é maior que 0
e 0 quando menor.

\begin{equation}
    \label{eq:funLimiar}
    o(v) = \left\{
        \begin{array}{lr}
            1 & :se\  v(x) > 0\\
            0 & :se\  v(x) < 0
        \end{array}
    \right.
\end{equation}

Ainda segundo  \citeonline{knight} o  \textit{perceptron} se  caracteriza pelos
pesos  e pela  definição  do valor  da  função  de ativação,  e  o processo  de
aprendizagem se caracteriza pela modificação desses pesos e valores.

Porem a  utilização de  sistemas simples com  somente um  \textit{perceptron} é
insuficiente na solução de muitos problemas que segundo \citeonline{knight} ele
sozinho  é incapaz  de traçar  hiperplanos  capazes de  resolver problemas  não
lineares, no  exemplo apresentado  por \citeonline{knight} neste  é apresentado
que  enquanto um  neurônio  artificial  é capaz  de  reproduzir corretamente  o
comportamento de um porta logica E ou OU este não consegue sintetizar uma porta
OU-exclusivo, com isso é definido um limite ao \textit{perceptron} já que este
é incapaz de resolver algumas classes de problemas.

\subsubsection{Redes neurais \textit{feedforward}}

Ainda considerando  a incapacidade do  \textit{perceptron} de uma  única camada
modelar algumas superfícies \citeonline{knight} apresenta que se empregado mais
de  uma  camada seremos  capazes  então  de  representar esses  problemas  mais
complexos. A essa arquitetura de organização de neurônios se dá o nome de redes
neurais de  múltiplas camadas, e quando  a alimentação é na  direção da entrada
para a saída será classificada também como \textit{feedforward}.

Podemos  entender  uma  rede  neural   de  múltiplas  camadas  em  três  partes
essenciais, a camada  de entrada, a escondida  e por último a  camada de saída.
Sendo a camada  de entrada aquela que recebe as  características do conjunto de
dados. O nome  de \textit{feedforward} é dado devido a  entrada ser apresentada
primeiramente a camada  de entrada e as  ativações fluírem até a  saída. Logo o
resultado da  rede será encontrado  na camada de saída  após passar por  toda a
rede  em uma  única direção.  Visualmente podemos  expressar a  rede segundo  a
\autoref{fig:neuralNetwork}.

\begin{figure}[ht]
    \centering
    \caption{Representação da ligação entre \textit{perceptron} em uma rede
    neural}\label{fig:neuralNetwork}
    \includegraphics[width=.5\linewidth]{images/neuralNetwork.png}
    \source{\citeonline{haykin2009}}
\end{figure}

Sendo os  parâmetros a  serem definidos  em uma rede  neural somente  os pesos,
$w_i$, definimos que  estes serão inicializados como  valores aleatórios, sendo
reajustados uma vez a cada passagem do aprendizado.

Para avaliação dos  pesos é necessário utilizar uma função  de calculo do erro,
como este trabalho consiste na realização regressão o calculo do erro será dado
pela função de erro absoluto médio conforme \autoref{eq:mae}.

\begin{equation}\label{eq:mae}
    MAE = \frac{1}{n}\sum_{i=1}^{n}{|(Y_i - \hat{Y}_i)|}
\end{equation}

\subsubsection{Retro propagação}

A atualização  dos pesos ocorre  a cada iteração  sobre os valores  de entrada,
assim,  suas  saídas  são  comparadas  com  os  valores  reais  e  computado  o
valor  do erro.  Tendo os  valores  dos erros,  $L$,  esse valor  é aplicado  a
\autoref{eq:backpropagation} e  então os pesos  da rede neural  são atualizados
para a  nova iteração,  sendo aplicado  uma taxa  de aprendizado,  $\alpha$, ao
valor que será corrigido os pesos.

\begin{equation}\label{eq:backpropagation}
    w_{n+1} = w_n - \alpha \frac{\partial L(x,w_t)}{\partial w_t}
\end{equation}

\subsubsection{Avaliação e seleção do modelo}

Após  o treinamento  do  modelo temos  de  avaliar a  capacidade  do modelo  de
generalizar  para  dados  ainda  não  apresentados a  eles,  esse  conceito  de
generalização  é descrito  por \citeonline{haykin2009}  como um  dos principais
objetivos de um modelo neural.

Para avaliarmos a capacidade de generalização normalmente é separado uma porção
dos  dados, normalmente  em uma  proporção de  30\%, assim  durante a  etapa de
treinamento serão  utilizados a porção  maior dos dados  e após o  modelo estar
treinado  é verificado  a qualidade  utilizando a  função de  erro já  definida
anteriormente mas agora no conjunto de teste.

Já  que  durante  a  etapa  de  aprendizado  o  modelo  só  obterá  informações
do  conjunto  de   trinamento  se  faz  necessário   algumas  estrategias  para
impedir  que  o  modelo  se  especialize no  conjunto,  essa  especialização  é
conhecida por  \textit{overfit}, isto pode  causar a incapacidade do  modelo em
prever  corretamente  os  dados  que  ainda não  foram  lhe  apresentado.  Para
impedir  isto  podemos  realizar   os  seguintes  procedimentos  descritos  por
\citeonline{deepLearning}.

\begin{enumerate}
    \item Validação cruzada\\
        O conjunto de dados é divido em sub conjuntos, \textit{folds}, e a rede
        neural é treinada  utilizando $k-1$ \textit{folds}, sendo  $k$ o número
        total de conjuntos  criados, e o modelo é validado  no conjunto deixado
        de  fora do  treinamento.  Ocorrerá  ainda a  mudança  do conjunto  que
        servirá para validação, assim impediremos  que a rede se especialize em
        um conjunto  especifico. Na \autoref{fig:crosvalidation} o  conjunto de
        entrada é dividido  em três \textit{folds} e o  treinamento é realizado
        nas três divisões  criadas, sendo os conjuntos em  azul utilizados para
        treinamento e aqueles em vermelho utilizados para avaliar o modelo, e o
        modelo  é  avaliado  conforme  um  método, $L_{cv}$,  que  reúna  os  a
        avaliação de todos, $L = L_{cv}(L_1, L_2, L_3)$.

        \begin{figure}[ht]
            \centering
            \caption{Divisão da entrada em três\textit{folds}}\label{fig:crosvalidation}
            \includegraphics[width=.5\linewidth]{images/cross_validation.png}
            \source{Elaborado pelo autor}
        \end{figure}

    \item Regularização\\
        Tem  como objetivo  manter os  pesos do  modelo baixos.  O procedimento
        consiste  em alterar  a função  do erro  adicionando a  ela o  custo do
        pesos, isso é  feito conforme a \autoref{eq:regL1}, sendo  $L$ a função
        de perda anterior e $L_{reg}$ a  regularizada, $w$ é os pesos do modelo
        e $\lambda$  é a taxa de  regularização, se selecionado um  valor muito
        alto os  pesos tenderão a  $0$ e o efeito  prático será o  contrario ao
        desejado  e o  modelo passará  a ser  incapaz de  representar também  o
        conjunto de entrada.

        \begin{equation}\label{eq:regL1}
            L_{reg} = L + \lambda \sum{|w|}
        \end{equation}
\end{enumerate}

Como  já  apresentada  existem  diversas definições  a  serem  realizadas  para
produção  do  modelo que  contemple  os  requisitos  do modelo.  Podemos  então
realizar testes nesses diversos modelos  possíveis e escolher aquele que melhor
se adeque segundo a função de  erro definida, esse procedimento é conhecido por
busca em grade,  realizando a avaliação do modelo para  todas as combinações de
parâmetros definidos na grade.

\chapter{Trabalhos relacionados}

Com objetivo de entender e analisar como os modelos estudados se comportavam,
foram analisados diversos trabalhos. Sendo inicialmente avaliados os estudos
com foco na utilização dos modelos estatísticos e após isso a busca por textos
que observaram o comportamento de modelos de aprendizado de máquina. Além
desses casos, foi buscados trabalhos que utilizam ambos modelos em formato de
comparação, semelhante ao objetivo deste trabalho.

\citeonline{vinay}   utilizou  modelos   ARIMA  e   suas  variações   SARIMA  e
ARIMA-GARCH, para  previsão de trafego em  rodovias. Um de seus  desafios foi a
necessidade de predição em tempo real, ou seja, o modelo tinha de ser obtido ao
mesmo tempo  que os dados eram  gerados. Ele identificou que  modelos ARIMA tem
uma alta complexidade para serem encontrados,  já que ele usou uma abordagem de
busca em  grade para  identificar o  modelo adequado,  utilizando a  métrica de
média das somas quadradas dos erros para avaliação.

\citeonline{reza}  propôs um  modelo  ARIMA modificado  acrescentando ao  valor
previsto a  soma das medias dos  erros para encontrar um  modelo mais adequado.
Sua  abordagem obtive  resultados  melhores que  aqueles observados  utilizando
somente ARIMA\@.

Já \citeonline{matias} comparou ARIMA com outros modelos de base estatística, e
propôs  um modelo  hibrido entre  eles, para  previsão de  demanda de  táxis na
cidade de Porto em Portugal, com objetivo de melhorar a distribuição dos táxis.
Um de seus  desafios foi combinar a informação de  geolocalização com as séries
das  demandas por  corridas. Como  resultado  ele foi  capaz de  obter um  erro
inferior a 26\% na previsão de corridas utilizando modelo proposto.

\chapter{Desenvolvimento}\label{chap:desenv}
Como colocado na \autoref{sec:seriesTemporais} a capacidade de se prever séries
temporais tem  grande importância,  e uma  de suas  principais aplicações  é na
previsão  de indicadores  econômicos, como  o S\&P500,  um índice  mantido pela
Standard \& Poor's desde 1923, indexando os  valores de 500 ativos em bolsas de
valores e  servindo como um indicador  geral do comportamento do  mercado. Logo
foi obtido os dados do S\&P500 para comparar os modelos apresentados e observar
as previsões que estes foram capazes de realizar considerando essa série.

Para   podermos   compreender   o   comportamento  dos   modelos   com   outros
tipos   de  séries   foi  também   selecionada  a   série  já   apresentado  na
\autoref{sec:seriesTemporais} que contem os dados  da concentração de $CO_2$ na
atmosfera. A  importância de  avaliar comportamento  com essa  série se  dá por
conta do  se diferenciar da  série econômica  por ter sazonalidade  e tendência
muito mais claras.

Durante  toda  a  etapa  de   desenvolvimento  foi  utilizada  a  linguagem  de
programação python em conjunto com jupyter  para a análise das séries, produção
dos modelos  e avaliação. Especificamente  para os modelos  probabilísticos foi
utilizado a  biblioteca statsmodels\footnote{\url{https://www.statsmodels.org}}
e  tensorflow\footnote{\url{https://www.tensorflow.org/}}  para os  modelos  de
aprendizado de máquina.  Além delas foram utilizadas a  biblioteca seaborn para
produção  dos gráficos  e  pandas em  conjunto com  numpy  e scikit-learn  para
importar e realizar as modificações necessárias dos dados.

As observações das séries podem ser obtidas
online\footnote{\url{https://datahub.io/core/s-and-p-500}}\footnote{\url{https://datahub.io/core/co2-ppm}}.
Na   \autoref{fig:sp500}  e   \autoref{fig:co2}  observamos   a  plotagem   das
observações  do   índice  S\&P500  e   as  leituras  do  $CO_2$   na  atmosfera
respectivamente.

\begin{figure}[ht]
    \centering
    \caption{Gráfico das observações do índice S\&P500}\label{fig:sp500}
    \includegraphics[width=.5\linewidth]{images/sp500.png}
    \source{Elaborado pelo autor}
\end{figure}

A  divisão do  conjunto  de treino  e  teste  foi realizado  de  maneira a  ser
utilizado 70\% dos dados durante o treinamento e 30\% durante a validação.

Após a análise da série foi encontrado os modelos que mais se adequem as séries
apresentadas e validada  a capacidade deste modelo prever um  dia adiante. Para
tornar a  comparação justa  foi definido algumas  considerações aos  modelos de
aprendizado, como a quantidade de observações consideradas para a previsão.

\section{Análise da série}

Seguindo as etapas para construção do modelo foi realizada a análise dos dados.
O  objetivo  era identificar  as  características  da  série,  como se  esta  é
estacionaria, e quanto  a existência de tendencia e  sazonalidade, sendo também
já realizada a remoção de \textit{outliers} que possam atrapalhar na construção
do modelo.

Já   na   análise   dos   gráficos  das   séries   na   \autoref{fig:sp500}   e
\autoref{fig:co2} fica  evidente o comportamento  não estacionário de  ambas as
séries, conclui-se  isso segundo  os critérios  definidos anteriormente.  Já se
aproveita para perceber a existência clara de tendência em ambos conjuntos.

Para  tornar  a  série  estacionaria é  necessário  realizar  inicialmente  uma
diferenciação.  Na \autoref{fig:co2diff}  temos  a  primeira diferenciação  das
leituras de $CO_2$, já para  a série financeira temos a \autoref{fig:sp500diff}
em sua primeira  diferenciação. Pela observação podemos concluir  que uma única
diferenciação foi suficiente em ambos os casos.

\begin{figure}[ht]
    \centering
    \caption{Primeira diferenciação dos dados do SP500}\label{fig:sp500diff}
    \includegraphics[width=.5\linewidth]{images/sp500diff.png}
    \source{Elaborado pelo autor}
\end{figure}

Quanto a sazonalidade é evidente a sua existência nas leituras de $CO_2$, sendo
esta anual e tendo que as leituras são mensais podemos dizer que a sazonalidade
se repete a cada  12 leituras, no entanto, tal constatação não  é tão clara nos
índices da  Standard \&  Poor sendo  necessários outros  métodos que  não foram
discutidos nesse trabalho para a sua definição.

Tendo sido realizada  a análise pode-se estimar que os  modelos ARMA não seriam
suficientes  e que  seria a  necessária  utilização do  modelo integrado,  alem
disso, seria adequado a aplicação do modelo com suporte a sazonalidade, SARIMA,
à série  contendo leituras  de $CO_2$,  no entanto,  por conta  da complexidade
adicional este não fez parte do desenvolvimento desse trabalho.

\section{Definição do modelo probabilístico}

%TODO Definição do modelo CO2

Compreendido  o  comportamento  da  série  se definiu  a  correlação  entre  as
observações para possibilitar a construção  do modelo probabilístico, usando do
gráfico  da  função  de autocorrelação  apresentado  na  \autoref{fig:sp500acf}
em   conjunto  com   o  gráfico   da  função   de  autocorrelação   parcial  da
\autoref{fig:sp500pacf} foi compreendido seguindo  o modelo de \citeonline{box}
que por conta  de ambos gráficos apresentarem somente um  valor significativo o
modelo probabilístico escolhido  para representar a série S\&P500  foi o modelo
ARIMA(1,1,1), sendo este hibrido do modelo AR(1) e MA(1) com uma integração.

\begin{figure}[ht]
    \centering
    \caption{Gráfico dos 40 primeiros elementos da função de autocorrelação da
    série S\&P500}\label{fig:sp500acf}
    \includegraphics[width=.5\linewidth]{images/sp500acf.png}
    \source{Elaborado pelo autor}
\end{figure}

\begin{figure}[ht]
    \centering
    \caption{Gráfico  dos 40  primeiros elementos  da função  de autocorrelação
    parcial da série S\&P500}\label{fig:sp500pacf}
    \includegraphics[width=.5\linewidth]{images/sp500pacf.png}
    \source{Elaborado pelo autor}
\end{figure}

\section{Definição do modelo utilizando aprendizado de máquina}

Já para  o desenvolvimento do modelo  neural não foi necessária  uma observação
profunda da  série, no entanto,  exigiu uma parametrização muito  mais complexa
do  modelo,  observando como  o  modelo  convergia considerando  os  parâmetros
escolhidos e realizando  uma busca em grade extensiva para  encontrar um modelo
com boa capacidade representativa.

Antes da etapa de parametrização  foram realizadas alguns pré-processamentos, o
primeiro foi  em vista  de escalar a  série para o  intervalo 0  e 1, já  que a
função  de  ativação  utilizada  tem  esse  intervalo  como  saída.  Para  isso
foi  utilizado o  método de  \textit{MinMaxScaler} da  biblioteca sklearn,  que
matematicamente pode ser representado  como visto na \autoref{eq:minmaxscaler},
sendo $MAX$ e  $MIN$ o maior e  menor valor respectivamente no  conjunto após o
procedimento.

\begin{equation}
    \begin{split}\label{eq:minmaxscaler}
        &X_{std} = \frac{X - \min X}{\max X-\min X}\\
        &X_{scaled} = X_{std} * (MAX-MIN)+MIN
    \end{split}
\end{equation}

Na \autoref{tab:gridsearch} observamos todos os parâmetros testados na busca em
largura.

\begin{table}[ht]
\centering
\caption{Possibilidades dos parâmetros da busca em grade}\label{tab:gridsearch}
\begin{tabular}{l l}
\multicolumn{1}{c}{Parâmetro}        & \multicolumn{1}{c}{Possibilidades}  \\
    \toprule
    Número de camadas                & 1 \ldots 4                          \\
    Número de unidades por camada    & 1 \ldots 20                         \\
    $\lambda$ regularização          & 0.00001 \ldots 0.0001               \\
    Função de ativação               & $relu$, $sigmoid$                   \\
    Função de perda                  & MSE, MAE                            \\
    Iterações                        & 20 \ldots 500
\end{tabular}
\source{Elaborado pelo autor}
\end{table}

Uma característica que foi logo  observada nas primeiras execuções anteriores a
aplicação  da regularização  foi o  rápido \textit{overfit}  sobre os  dados de
treinamento como  visto na \autoref{fig:sp500_overfit}, mesmo  sendo aplicada a
validação  cruzada, e  ainda como  visto na  \autoref{fig:iter_sp500_overfit} a
especialização para o conjunto de treino foi muito rápida, assim foi aplicada a
regularização e após se tornou frequente  encontrar bons modelos para as séries
observadas.

\begin{figure}[ht]
    \centering
    \caption{Gráfico  da  comparação  do  previsto   e  real  para  o  conjunto
    de   treino   e   teste   para   a   série   de   observações   do   índice
    S\&P500}\label{fig:sp500_overfit}
    \minipage{0.50\linewidth}
        \includegraphics[width=\linewidth]{images/sp500_overfit_train.png}
    \endminipage\hfill
    \minipage{0.50\linewidth}
        \includegraphics[width=\linewidth]{images/sp500_overfit_test.png}
    \endminipage\hfill
    \source{Elaborado pelo autor}
\end{figure}

\begin{figure}[ht]
    \centering
    \caption{Gráfico da função de perda em  função do números de iterações para
    a série S\&P500}\label{fig:iter_sp500_overfit}
    \includegraphics[width=.5\linewidth]{images/sp500_overfit_iter.png}
    \source{Elaborado pelo autor}
\end{figure}

Para os dados  da Standard \& Poors  o modelo selecionado a partir  da busca em
grade  foi com  duas camadas,  sendo a  primeira camada  com 13  neurônios e  a
segunda com somente um  neurônios já que esta é a camada de  saída. A função de
ativação de foi a $relu$ e  o $\lambda$ da regularização ficou como $0.000001$.
A função de  perda selecionada foi $MSE$ e 300  iterações foram suficientes. Já
que  o modelo  probabilístico  tem AR(1)  foi fixado  em  uma única  observação
no passado para a realização da previsão.

\chapter{Resultados}\label{chap:result}

A  partir  dos  modelos  gerados   foram  obtidos  os  resultados  apresentados
na   \autoref{tab:resultadosp500}   e  o   gráfico   do   conjunto  de   testes
comparando  os   resultados  obtidos  com   os  valores  são   apresentados  na
\autoref{fig:comparesp500}.  Observando  os  resultados  é claro  que  os  dois
modelos conseguiram exito  na tarefa de aproximar o comportamento  da série. Em
termos  comparativos o  modelo neural  obtive resultado  um pouco  inferior, na
ordem de $0,6\%$.

\begin{table}[ht]
    \centering
    \caption{Valores do erro para a série S\&P500}\label{tab:resultadosp500}
    \begin{tabular}{ll}
        \multicolumn{1}{c}{Modelo} & \multicolumn{1}{c}{MSE} \\
        \toprule
        MLP                        & 0,0002101               \\
        ARIMA                      & 0,0002088
    \end{tabular}
    \source{Elaborado pelo autor}
\end{table}

\begin{figure}[ht]
    \centering
    \caption{Gráfico comparativo entre os modelos obtidos para a série
    S\&P500}\label{fig:comparesp500}
    \includegraphics[width=.5\linewidth]{images/sp500_prediction_compare.png}
    \source{Elaborado pelo autor}
\end{figure}

\chapter{Conclusões}\label{chap:concl}

Objetivo deste trabalho  foi produzir e avaliar modelos  preditivos para series
temporais utilizando  algorítimos estatísticos e  de aprendizado de  máquina. É
comum  em  trabalhos  a  utilização  de métodos  probabilísticos  quando  se  é
realizada a tarefa de previsão de séries, mais especificamente o modelo hibrido
ARIMA proposto por \citeonline{box}. No entanto modelos baseados em algorítimos
de aprendizado  de máquina  tomaram notoriedade nos  últimos anos,  logo, neste
trabalho  foi comparado  estes  modelos  para entender  os  suas capacidades  e
observar os seus desafios particulares.

Para  permitir a  avaliação  foi  necessária a  compreensão  da construção  dos
modelos. Enquanto  o proposto por \citeonline{box}  apresentou uma complexidade
muito  superior na  etapa de  análise da  série, já  que esse  modelo pode  ser
entendido como dependente de  diversas intervenções para melhor parametrização,
o  modelo  de  aprendizado,  utilizando redes  neurais  de  múltiplas  camadas,
apresentou  uma  necessidade minima  de  compreensão  dos dados  estudados,  no
entanto, sua complexidade se apresentou durante a etapa de treinamento.

Quanto aos resultados,  podemos concluir que os modelos  utilizados foram muito
similar em seu desempenho. Vale notar que possivelmente os resultados não foram
expressivas  na conclusão  de superioridade  de  um modelo,  devido a  aparente
simplicidade da série utilizada para comparação, como também pode se discutir a
semelhança matemática  entre os modelos  utilizados. Quanto a métrica  de erros
quadrados  médios utilizada  para a  avaliação, o  modelo ARIMA  teve resultado
superior em uma ordem ínfima, 0,6\% em relação ao modelo de redes neurais.

O  modelo probabilísticos  obtido foi  um modelo  hibrido ARMA,  de ordem  1 do
processo autorregressivo e  ordem 1 para o processo de  medias móveis, e também
foi realizado uma  diferenciação já que a série apresentou  tendencia durante a
análise, e  se faz necessária a  diferenciação para para obtenção  de uma série
estacionaria, característica requerido  pelo modelo. Durante a  análise não foi
identificada sazonalidade.

Para  obtenção do  modelo de  redes neurais  a mudança  dos dados  se resumiram
a  realizar  uma  escala  para  valores,  sem  necessária  maior  avaliação  do
comportamento, já  que segundo  \citeonline{haykin} algorítimos  de aprendizado
são ditos  dirigido por dados.  No entanto durante  a etapa de  treinamento foi
necessária  a  realização  de  diversos  testes para  encontrar  o  modelo  que
melhor  se adequava,  além da  aplicação de  validação cruzada  e regularização
para  diminuir a  ocorrência de  \textit{overfit}. Por  meio desse  processo se
identificou uma rede neural de duas camadas,  sendo a de entrada com 9 unidades
de processamento, \textit{perceptron}, e a segunda com um único neurônio, sendo
essa camada a de saída e representando a previsão um passo a diante.

Conclui-se que os  modelos são suficientes para a tarefa,  no entanto, temos de
observar que o modelo estatísticos torna  a parametrização uma etapa muito mais
complexa que o modelo de aprendizado. Assim  a escolha do modelo pode ser feita
analisando capacidade de  análise de quem constrói o modelo,  ou o entendimento
de  como os  dados poderão  se  comportar, já  que  o modelo  de aprendizado  é
dirigido pelos dados, logo, sua capacidade de se adaptar a novos comportamentos
é superior ao modelo probabilístico.

\section{Trabalhos futuros}

Um  possível trabalho  futuro é  a  avaliação de  diferentes modelos  hibridos,
se  aproveitando  da  capacidade   do  modelo  probabilísticos  em  representar
comportamento linear e também a capacidade  de modelos de aprendizado em séries
não  lineares, como  feito por  \citeonline{oCaraLaDoModeloHibrido}. Uma  outra
possibilidade é a  utilização de redes neurais recorrentes,  que se diferenciam
de modelos \textit{feedforward}  por possuir memorio, uma  arquitetura de redes
neurais  que  tem  apresentado  bons  resultados é  a  LSTM,  alguns  trabalhos
como  \citeonline{oDoCaraQueComparaArimaComLSTM}  demonstram   que  é  possível
obter  resultados superiores  com sua  aplicação. Podemos  ainda estudar  essas
comparações com séries de  comportamento diferente, e consequentemente utilizar
modelos estatísticos mais completos, como o SARIMA ou SARIMAX\@.

\postextual

\bibliography{referencias}

\end{document}
